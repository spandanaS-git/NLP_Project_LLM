{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620,
     "referenced_widgets": [
      "7e5dd0b1b3d643728e270c826f5fcf38",
      "59672c5c74a041bb92f4b3acf5dd4cc2",
      "79ebe213e33644458d99253fa44a0d77",
      "0bc09fe8f1ff44d585be178c590e2389",
      "8b7ffb7838c94ee5a4a77c3d365c5889",
      "1831ac401ac444789f96ba2a364f1e36",
      "aa8e7bb723074c5683021d2bb219bacb",
      "f8b0d39a6a624680b857b6be5a15cc11",
      "85924d3370da401cb29746dee4474398",
      "1ff8dd9cb89e47d78e74ba873b6ccc2e",
      "1de2415519324b44a263d35366281100",
      "63225dd3adc94c4bad20fccce4514861",
      "71b72795ba9a434bb5f7cf3849422802",
      "68dc84d747304d6399dc59ffac1a6b4f",
      "5a2c5a62ea4b4883a3889ceb315907b1",
      "2686faf585d5485e930b1588bf6441d9",
      "b8279183874645a895b2b4f630798bf3",
      "78220d8af5ea4e04940198969fc295a2",
      "2e54fb4310e4428ca0b0cf1a5647f02d",
      "d0a423a0079f4b4e877e523b88e2482a",
      "185f85c73f834921930bad32bc30a5ee",
      "c52a3c53bf05488e8b12da23e2dc54a4",
      "6fed5e0ec94d410eac92cd8d08f0d033",
      "45ccabc7a5aa4409890a4b270a417178",
      "d0d4c9cf072d4e0591850044a833d6ec",
      "b1f631665fa14c29bdbbf88bdb2a7489",
      "01cf6c314a194f6ea76ea58fa286db0f",
      "7cb463a650584944974d1244158710e3",
      "85cd14708e164386b9324c936d960f7f",
      "c73961c34cd54bbf9820d98af993b7f6",
      "03e11d5014ba4f488532ebdeaa3f24fa",
      "d93131af218f4a3287bd1e2c3d6eca54",
      "af35fe5156144b9aa32328680526cf98",
      "7fba6da3ba5e465ca97b78cb24c0390b",
      "55cd6aa8d9ec49a5af72e1825e86235d",
      "a2fe0146e96f4c86af10de2063bac769",
      "a6bebe9fb1ff47f5804c8ee02664c7ce",
      "dfb44606a58840b19ad951b5a547672c",
      "75ab7ac7bc834713a783b60eeb3ecd44",
      "0085b9eb8d1346ae88202facfb46e467",
      "1e997e3696294a8eae3682e44bcfa3b0",
      "6e15e27b0cce49beb1e5b810dd3896d6",
      "167207b4da45421a91ca420aa1ba3d7f",
      "c05453c11fad4d8d9adaf6c85405fbd4",
      "1a9feee177c4436fa92273facb75bf4a",
      "b5e3240191d84feebc763451ca2d5c59",
      "9630d1aab9c64acf94479ff160d3fa35",
      "219b2022a3e8433289ff8692780c563b",
      "5c4ec65ce4b6438c92e2e4a2321fa107",
      "6a2f74edc4eb48aea92323d3163898b5",
      "c0223a38cf5b4d2286ad64c0508b204d",
      "6060949de2664de2ae80f1e8ca0389e0",
      "228c062063084de3884b3667666f8329",
      "998b93a86aaf48008474a411f065cd14",
      "e61f6d4f38044fa69535af02507bc1c7",
      "1376c2997ab84e8bac9a0823d6e74b5a",
      "04a2f6a7389b45cfb8c6a8fe18e3c2f3",
      "5b14071f4fa543c28ca77fcba092fbe2",
      "07cb806d3e1e4b578b0eb78a54ce9b53",
      "85d1ff25c3d44f49bfa396f67c505124",
      "87d6d14c88ed4688b2c8669870c4fd59",
      "5e9271908c1941f8b90e4d9a8c6016f8",
      "de7b697c1ec244918ee93e8f0c5ed942",
      "e49f68211c1a4147b40d94a47144814e",
      "feb594c62fca469db1065165c3f68cac",
      "0dedcc50345740d4bd7d961a8f812008",
      "c71c20dd7a974a9d8613d99c1a1c9263",
      "6a9ee33b2b0c48a9a03115a0e52d723d",
      "63637282d3b04d6b8c49971e0b0e7634",
      "39e07932438243ac930b0b92e5f73cab",
      "e374ae14daf9449eb1ca95cec322d24e",
      "24d402e1a2cf40248e60f8b2222642b2",
      "638df57b4cf1423aafd77d6e347f46b0",
      "167b43c2bc394996876a2d9e58c9201e",
      "1a7c3b1bc7a74b899fa9d6d5b631ca49",
      "d4997c0fffae4773a7c968222cb00085",
      "df666c1d7fbc4a709de871bf7e3814e9",
      "622c3d7589c1449f9b4fe9d8050e73fb",
      "96593b07b3f048d2adb5ceb96a89c590",
      "298fd7415b3d4eb994afc92d92e3d568",
      "5460445849f64c02849538913fc7d4ad",
      "fcda137fd7ec4ddab1fd4b49434bdc15",
      "db60557f51014ee99d81a3c404a629f7",
      "04ccb4ad7ce248ada090822393cec57c",
      "7d1f15fb20244caeade6ad932ad7f796",
      "efa49146c2ab4100a3b552be2a502067",
      "f491979c9ae94423b3b045e74038f07a",
      "35e4ce43b1b34dcea4b3f47399efcf40"
     ]
    },
    "id": "gp3PvdtY73nk",
    "outputId": "d9340474-6322-4778-c9f9-5bb280c7fda2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5dd0b1b3d643728e270c826f5fcf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63225dd3adc94c4bad20fccce4514861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medqa.py:   0%|          | 0.00/5.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fed5e0ec94d410eac92cd8d08f0d033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/7.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fba6da3ba5e465ca97b78cb24c0390b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/964k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9feee177c4436fa92273facb75bf4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/997k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1376c2997ab84e8bac9a0823d6e74b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71c20dd7a974a9d8613d99c1a1c9263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622c3d7589c1449f9b4fe9d8050e73fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1273 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'uid', 'question', 'metamap', 'target', 'answers'],\n",
      "        num_rows: 10178\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['idx', 'uid', 'question', 'metamap', 'target', 'answers'],\n",
      "        num_rows: 1272\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['idx', 'uid', 'question', 'metamap', 'target', 'answers'],\n",
      "        num_rows: 1273\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the MedQA dataset (US version)\n",
    "dataset = load_dataset(\"VodLM/medqa\", \"us\")\n",
    "\n",
    "# Check available splits\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJ0H8aXS79ef",
    "outputId": "e52fa650-97f7-4ea7-888c-d3259e7d6e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'uid': 'train-0', 'question': 'A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?', 'metamap': '23 year old pregnant woman weeks presents burning urination states started 1 day worsening drinking water taking cranberry extract feels well followed by doctor pregnancy temperature 97 36 blood pressure mmHg pulse 80 min respirations min oxygen saturation 98 room air Physical exam notable absence costovertebral angle tenderness gravid uterus following best treatment patient', 'target': 3, 'answers': ['Ampicillin', 'Ceftriaxone', 'Doxycycline', 'Nitrofurantoin']}\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "print(train_data[0])  # Print the first data point\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert dataset to pandas DataFrame\n",
    "train_data = dataset[\"train\"].to_pandas()\n",
    "test_data = dataset[\"test\"].to_pandas()\n",
    "validation_data = dataset[\"validation\"].to_pandas()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5oOg0IcY8BcB",
    "outputId": "4c185046-b5de-4865-8e01-6b3087e85c2f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 10178,\n  \"fields\": [\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 10178,\n        \"samples\": [\n          8505,\n          3130,\n          718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10178,\n        \"samples\": [\n          \"train-8505\",\n          \"train-3130\",\n          \"train-718\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10176,\n        \"samples\": [\n          \"A 67-year-old man presents to the emergency department after a suicide attempt. The patient was found in his apartment by his grandson with wrist lacerations. He was rushed to the emergency department and was resuscitated en route. The patient has a past medical history of ischemic heart disease and depression. His pulse is barely palpable and he is not responding to questions coherently. His temperature is 98.2\\u00b0F (36.8\\u00b0C), blood pressure is 107/48 mmHg, pulse is 160/min, respirations are 14/min, and oxygen saturation is 99% on room air. The patient is started on blood products and his blood pressure improves to 127/55 mmHg after 3 units of blood. On physical exam, the patient complains of numbness surrounding his mouth and pain in the location of the lacerations of his wrists. Which of the following best describes the laboratory findings in this patient?\",\n          \"A healthy 31-year-old woman comes to the physician because she is trying to conceive. She is currently timing the frequency of intercourse with at-home ovulation test kits. An increase in the levels of which of the following is the best indicator that ovulation has occurred?\",\n          \"A 14-year-old boy is rushed to the emergency room after he became disoriented at home. His parents say that the boy was doing well until 2 days ago when he got sick and vomited several times. They thought he was recovering but today he appeared to be disoriented since the morning. His vitals are normal except shallow rapid breathing at a rate of 33/min. His blood sugar level is 654 mg/dL and urine is positive for ketone bodies. He is diagnosed with diabetic ketoacidosis and is managed with fluids and insulin. He responds well to the therapy. His parents are told that their son has type 1 diabetes and insulin therapy options are being discussed. Which of the following types of insulin can be used in this patient for the rapid action required during mealtimes?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metamap\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10175,\n        \"samples\": [\n          \"62 year old woman type 2 diabetes mellitus physician 3 month history fatigue weakness hemoglobin concentration weeks blood pressure mm Hg Examination shows lower extremity edema Serum studies show K 5 mEq Phosphorus mg dL Urea nitrogen Creatinine 2 following best parameter early detection patients renal\",\n          \"year old teenager presents clinic parents headaches loss of vision began months headaches throbbing mostly forehead severe to affect daily activities not menarche Past medical history takes medication parents alive well Today blood pressure 70 mm Hg heart rate 90 min respiratory rate min temperature 98 Breasts pubic hair development Tanner Blood work collected MRI performed result shown Inhibition following hormones most likely explanation patient's signs symptoms\",\n          \"A 10 year old boy Sri Lanka suffers autosomal dominant condition hyperimmunoglobulinemia eosinophilia suffers recurrent infections takes antibiotic chemoprophylaxis STAT3 mutation analysis performed to confirm diagnosis Job syndrome Eosinophilia Eczema Hay fever Atopic dermatitis Recurrent skin lung infections Bronchial asthma combination symptoms characteristic condition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-baae7335-da9f-4eaf-996c-253366349844\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>uid</th>\n",
       "      <th>question</th>\n",
       "      <th>metamap</th>\n",
       "      <th>target</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train-0</td>\n",
       "      <td>A 23-year-old pregnant woman at 22 weeks gesta...</td>\n",
       "      <td>23 year old pregnant woman weeks presents burn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Ampicillin, Ceftriaxone, Doxycycline, Nitrofu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train-1</td>\n",
       "      <td>A 3-month-old baby died suddenly at night whil...</td>\n",
       "      <td>3 month old baby died night asleep mother died...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Placing the infant in a supine position on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train-2</td>\n",
       "      <td>A mother brings her 3-week-old infant to the p...</td>\n",
       "      <td>mother week old infant pediatrician's office c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Abnormal migration of ventral pancreatic bud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>train-3</td>\n",
       "      <td>A pulmonary autopsy specimen from a 58-year-ol...</td>\n",
       "      <td>pulmonary autopsy specimen 58 year old woman d...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Thromboembolism, Pulmonary ischemia, Pulmonar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train-4</td>\n",
       "      <td>A 20-year-old woman presents with menorrhagia ...</td>\n",
       "      <td>20 year old woman presents menorrhagia past ye...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Hemophilia A, Lupus anticoagulant, Protein C ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baae7335-da9f-4eaf-996c-253366349844')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-baae7335-da9f-4eaf-996c-253366349844 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-baae7335-da9f-4eaf-996c-253366349844');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9a1d838c-53a8-4988-91ea-ace3eb9294ba\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a1d838c-53a8-4988-91ea-ace3eb9294ba')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9a1d838c-53a8-4988-91ea-ace3eb9294ba button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   idx      uid                                           question  \\\n",
       "0    0  train-0  A 23-year-old pregnant woman at 22 weeks gesta...   \n",
       "1    1  train-1  A 3-month-old baby died suddenly at night whil...   \n",
       "2    2  train-2  A mother brings her 3-week-old infant to the p...   \n",
       "3    3  train-3  A pulmonary autopsy specimen from a 58-year-ol...   \n",
       "4    4  train-4  A 20-year-old woman presents with menorrhagia ...   \n",
       "\n",
       "                                             metamap  target  \\\n",
       "0  23 year old pregnant woman weeks presents burn...       3   \n",
       "1  3 month old baby died night asleep mother died...       0   \n",
       "2  mother week old infant pediatrician's office c...       0   \n",
       "3  pulmonary autopsy specimen 58 year old woman d...       0   \n",
       "4  20 year old woman presents menorrhagia past ye...       3   \n",
       "\n",
       "                                             answers  \n",
       "0  [Ampicillin, Ceftriaxone, Doxycycline, Nitrofu...  \n",
       "1  [Placing the infant in a supine position on a ...  \n",
       "2  [Abnormal migration of ventral pancreatic bud,...  \n",
       "3  [Thromboembolism, Pulmonary ischemia, Pulmonar...  \n",
       "4  [Hemophilia A, Lupus anticoagulant, Protein C ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFgBODgZ9JLm",
    "outputId": "47dd9d6a-66a6-4b3b-938e-160a03c26607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses) (4.67.1)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/897.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398,
     "referenced_widgets": [
      "2bdf3d291ee24ceeb2f2ac18c955dce1",
      "f6ded9fea30c414b9ab2b978e76ded69",
      "93f9477f93924763b81f5a6d6429d6ae",
      "a0f4625a12eb4f35b5d3437a62292d51",
      "76d57aa067cb4d6d80ccbaf83117c8a6",
      "94df8804651e4c4b827fcd2056ddf721",
      "991b7c3e49764ddbb01954071a5e31d2",
      "745e26035a90454d881a224527ac8e5f",
      "abb722dfbecb4c488a83c777945094fd",
      "c1de526b0ea24742b275c8066bbc6f9b",
      "d98faec8f3e54eeda7a18ed3ddc25e94",
      "43d636a1ad8b4207bf613ff6d00a7cb8",
      "1f40d9a517214e60bdf1301a9c54868f",
      "7b74d232bf864d4bb78c3b2ed6d65b48",
      "7015d5c3d6ea4ea4821054ea487d4d91",
      "afbf110dce984cc194896e6c3b25cfeb",
      "804ed5a26ca4457887a5d2f827b7df59",
      "892314e0198a45fbae154867dc27d690",
      "3658bf9f365645399448e53676f54219",
      "31dfc56d2d2a48d3889fb01174d5fa57",
      "a32616e869d946d7b2411b73f5590f54",
      "cb607788d97742948d10c0ce99792265",
      "4d904c3e97604ac0a0d5cb38d2ef2254",
      "f33b6247ecab48daa46d0149f4eaac93",
      "a8c16b662e3c44879b4dbadb331bde73",
      "8714f3763ee641bea5b7a5fe636cd581",
      "c0dffb0f2ef24363a50687c65623d3ca",
      "80ac90f5de3246d9a03f0d6b43c5ca38",
      "05dfa6d6ca104316903eb917ec77de80",
      "1f457833cd9b4d868573386fada3af04",
      "a73b15b20e9f435d92ac9d0d3fe3a369",
      "6707d566d19641d48d2e521047a34590",
      "33c9b7fa73c140f4a9cfadbb0235bef5",
      "59d5af73246441ddb820fc58c1d03539",
      "86a22495acab443ea4c93f8d74396ec1",
      "1ca4ab4275e04356babd2d004fddfbbd",
      "4bbdd60c63c448d395875f3ff25f025a",
      "e0784ad351784cfa9a50336fec9c8716",
      "b30fda15ddcf4005b21127153a37da72",
      "bb868d17594a40a0aa606d137d0c32d7",
      "df55ba3695344656b0cddcc81764c9c1",
      "f3b544a356d14e0696ac577dd91870bf",
      "302d578cb43e47dca6fe9181bfcc09cf",
      "deb2fe132d1f4f86b09c9a8edbe15f63"
     ]
    },
    "id": "sfVpi9Oh75M4",
    "outputId": "908a9803-d93d-4e1f-e2d9-729435d8acd3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdf3d291ee24ceeb2f2ac18c955dce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/595 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d636a1ad8b4207bf613ff6d00a7cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/927k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d904c3e97604ac0a0d5cb38d2ef2254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/696k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d5af73246441ddb820fc58c1d03539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3185' max='3185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3185/3185 16:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.422400</td>\n",
       "      <td>1.404879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.411600</td>\n",
       "      <td>1.389022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.283800</td>\n",
       "      <td>1.415284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.977900</td>\n",
       "      <td>1.711698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>2.242815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/159 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 1.389021635055542, 'eval_runtime': 10.2577, 'eval_samples_per_second': 124.004, 'eval_steps_per_second': 15.5, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load BioGPT for causal language modeling\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Access the internal BioGptModel\n",
    "transformer_layers = model.biogpt.layers   # BioGPT uses this structure\n",
    "\n",
    "# Freeze all but the top 4 transformer blocks\n",
    "# num_layers = len(transformer_layers)\n",
    "# for i, layer in enumerate(transformer_layers):\n",
    "#     if i < num_layers - 4:\n",
    "#         for param in layer.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "# # Optionally freeze embeddings too\n",
    "# for param in model.biogpt.embed_tokens.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze last 6 layers of the transformer\n",
    "# for name, param in base_model.named_parameters():\n",
    "#     if any(f'model.decoder.layers.{i}' in name for i in range(8, 12)):\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "LETTER_MAP = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "def build_prompt(example):\n",
    "    question = example[\"question\"]\n",
    "    options = example[\"answers\"]\n",
    "    prompt = (\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"Options:\\n\"\n",
    "        f\"A: {options[0]}\\n\"\n",
    "        f\"B: {options[1]}\\n\"\n",
    "        f\"C: {options[2]}\\n\"\n",
    "        f\"D: {options[3]}\\n\"\n",
    "        \"Choose the best option (A, B, C, or D). Answer:\"\n",
    "    )\n",
    "    return prompt, LETTER_MAP[example[\"target\"]]\n",
    "\n",
    "class QAGenerationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt, answer = build_prompt(self.data[idx])\n",
    "        input_text = prompt + \" \" + answer\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Mask all prompt tokens with -100 so loss is only computed for the answer\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "        answer_token_ids = self.tokenizer(answer, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "        # Label: mask prompt with -100, retain only last tokens\n",
    "        answer_start = len(input_ids) - len(answer_token_ids)\n",
    "        labels = torch.full_like(input_ids, -100)\n",
    "        labels[answer_start:] = torch.tensor(answer_token_ids)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "# Convert dataframe to dict\n",
    "train_examples = train_data.to_dict(orient=\"records\")\n",
    "val_examples = validation_data.to_dict(orient=\"records\")\n",
    "\n",
    "train_dataset = QAGenerationDataset(train_examples, tokenizer)\n",
    "val_dataset = QAGenerationDataset(val_examples, tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./biogpt_qa_generation\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_safetensors=False,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "4501d59a774b4aa095c347d9922ba4c1",
      "415a814133b64caca27cfafb6eeb7dfc",
      "a976ae8e3bd6402db96e87119e3c7aaf",
      "8ba53b73575d4e94932d78bcebd0485a",
      "da3a524c925f4a3baa266ab5acc2b1a1",
      "b23022eea41245039c158bd8cffc8852",
      "f90cca1282c945118269607c20c19de1",
      "a9ea275835384d09aff719c65de142ec",
      "c98f019bd8934494b748fde1ec15a45c",
      "c51cf4c183914fe7a355659e6f2b2608",
      "a83e0e5584bf4453a150a5af53b691b2",
      "837d1cad436b464ca342acc47881f642",
      "480f825110ac442e8a6157f90f4f74d7",
      "d6de436400f4474cb8eddfab49a69bd5",
      "9782a5b7ff974ebc8accee9a7d886e4d",
      "3dc4ea304b8d471b97285e335f0143ca",
      "1be4922327d049bd9b9a8e964cb21d3f",
      "397308870cd441f4997e6a6fe1a5ee04",
      "b8b4bbffe0a2404ebe5c95ba963adc07",
      "025b82c832514d6eb6f46d54840c968d",
      "c5af63bb96ea49a090e77903ace0c9c2",
      "6841d55b56974f7abef6ec0c87ee941f",
      "60dbfdfe1a614b54990734e604db4c71",
      "76820bb1255e46ecb2c632c3a9e60e24",
      "5dd969a1eddf42c9bff780c9d395e734",
      "d496c73531d246999e17d1e3e1a88a07",
      "3db2b67a3bbe497a95e72e05c272fea4",
      "518e807a312645a680682e28f7c313ee",
      "79197a9a7557490ab06e1e3e5da2efbd",
      "cbd2a29791c047b885e46382498bc3db",
      "8fba03d5767e4b6594517ca3fdaf122a",
      "5fa837db79144cf5abc2284c319a374f",
      "6e3272156caf41d9b1a330e52c478aa4",
      "3c8991fb0a03417f9b8f707c967071be",
      "f5a27d9a096f4a12b80e20e346e44ea8",
      "2cb8e70bc3f34434a8240263b96ce8c4",
      "394c2a3726c74c2086b6e1b761628856",
      "20aa5f9059d24027a4bc60b2a9ebc2a0",
      "d144f0d8c7914bf78a89a0b54c4b72d6",
      "9ca84d1eebda4ff0a1d94a3dcf3c10c2",
      "1b784960c4b84dd78550ad0c12c24475",
      "c8c43457437840b48abbc5f88c889924",
      "46893724f421449d9d4d0844d7f5bfdc",
      "d0e3cfc6a2244200a7144bbc747a1f0c",
      "e2d07c0b0a3443798b884481dd95e289",
      "cef96ce81eda4c6cb2b912d190e09883",
      "873bfd84a1ca450aa1bdfc14d2e0f4e2",
      "59121205aa7e4c33971b52e9f75c6293",
      "6763f1dd4e7d4918a520a9d4d873f567",
      "a35219e2a63e4df58ae291ed8bf8bc44",
      "e0a6648bb19d4379bbdc214580de135e",
      "34c6c79f64d54bfaa3d9807104177cc1",
      "de2bd06edf9440a2b104bc20e7cd91cd",
      "46f16813f56547d9951548c6cd852980",
      "9ef65c8ba91d472dac8c5484f2de75fb",
      "15a35199c7aa47348edc93585fbc229a",
      "98d681b770554082bc45906d78f63031",
      "67e0f4f1537f4968ab63c0545ad60de4",
      "044bc9aa26d24a3084eb00d0ca8c47d0",
      "cb35cf38fd034237b16e93b68c989b29",
      "9897dfda907c4dc0842a2d5f1f8cc3b4",
      "276cf5de8fbc4b5db8b4954b4e68b84d",
      "10049501872547a980a141467a7b3a9a",
      "e9fc9604c7a34c13816dafad1c456b72",
      "c8278893cf6e4760b1fad4774e2dba07",
      "1a2d8ea2e4bd44fa965699bd61631f01",
      "32e2397ff8824f72b0ef7e1282c44850",
      "766f99e9e17541c99fc56712b52ce0cf",
      "9393715253b741e18318bb17d31be6ae",
      "b799b142cd814ef793d464743b96faeb",
      "18602008d18048349323f1e4b3d8d66b",
      "446ab0f24d3b4c2588d912eb2ffda48c",
      "b0e1235a3f1a49fc946205b569e0fe5d",
      "1b1208d810af46b5afb9125fd56e3a59",
      "9f4ca94104f6497780df46e966c90c09",
      "ea14ba2b932a45678a0134db563797e9",
      "be2a25aadcf04f87be26050f91039d01",
      "94d4b08b7f88447487742cf9fbb2f9f9",
      "4859eac35ee44b1c904cbd3fad84154b",
      "9bc7902cfd6d4b0aa3465d632aaf7dfb",
      "41523323ad684287b10ee476b5b4ceeb",
      "4b51157c7d9246f788d4c6974b38e5f4",
      "fbde333118594112baeb9b6e0cb8c287",
      "1cb986e0ae614c319da53459aeb2ba47",
      "3bc02d7c9feb4efba23ba0b835d2b4b9",
      "06603e7986c545ff83c31595017db217",
      "1aa096135bff4a20848cd14b4f163aff",
      "9c50e2dce15148d4b97f7796cf2ba1ef",
      "9880e675c7fa4c029b7459f98a1f15f0",
      "878c47b4bbc3428ebb949104c3087515",
      "8db5c0c794154ec1aea1d98566b21849",
      "3dec6e6a67124b7799dc2754dd81b693",
      "a5c5f2f430ab425aa6664bc438ee7a91",
      "bf366a2d09464db183979378fdb76dfb",
      "87369a92e5ab44da944e0ce86ac6b48a",
      "38dc9e294e604ea8bba25c8227dc5825",
      "b530be5a6a1d4be69e1d78eff19ccb2c",
      "fe90e6c1b7d34e81b6c56e4b65dd531e",
      "fac60e4a3047486d853fb16e786f5e1f",
      "7226f6c577be44b1b41bb63d74504edf",
      "3bf2e10d34d64051a33f1a789a871861",
      "3c92f187a5754b74b43d8dcf15da4ede",
      "69f1eea6328e4a3ab24649f4dfa463dd",
      "1a0266cb731a45778118f91cf604d3d5",
      "515159c1eeb1472ea536394a8f5434de",
      "41b0e4655ed441be818b4685aeff938f",
      "e27b415de47040298b5b519ea62e0890",
      "0ee14ff3ac0849faabc690d9702d1aff",
      "bd8c3e763ef64d09a73d62f4040eeb09",
      "01ff12372da24fa99c7b3b0ab9889651",
      "50cb616041fb4208bb15c3ad7f334ba0",
      "1058dfb9e96c46d8ad2106d865477b0c",
      "48a0cb9f96df49a283d7c58ee0730a3b",
      "e36cdecfd1b644458247a8e2cb17c29c",
      "fffbbf2ea8ca450eb06de4ace5480e21",
      "a465cb5799ef45adbb02358333d8e34b",
      "f1e8bf74b1da4d1a84b331bf5f615fe5",
      "a0c9b0b9c2da4238b3074e25b37f55bc",
      "3993ad0d9c274cf0a33659dc5f90d624",
      "a900b1f6d7214e8687cfad9bf90764f4",
      "c0932d4aac2348c494c81a02b5de38e1",
      "9f77783a7c6b47eca961575dd9c3df4a",
      "6818f1b0882b424980507d92057bbc83",
      "5e4c9b6c67204f5e90a36539672bc20a",
      "460a98b3320e43dd9e7f73b1519cd1bf",
      "82bce44b33cd43bebdefd5876cfe894f",
      "b2aa8d5384944daf93502f521ef1ab8e",
      "ecc638b71d844d37851a113637eed275",
      "389bdc6afd7a4114a9dadb03d44ec496",
      "d6686ec7ec824f8e8a5498d3fe39d753",
      "348d001c72524d6882cd9661f45f00f1",
      "443ede1cbb714f9dbff591e07b20e582"
     ]
    },
    "id": "Fh1-YBzevWGS",
    "outputId": "3f6b1c0a-60d5-4b9e-e8ef-cf1ceeeb62ff"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4501d59a774b4aa095c347d9922ba4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837d1cad436b464ca342acc47881f642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dbfdfe1a614b54990734e604db4c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8991fb0a03417f9b8f707c967071be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d07c0b0a3443798b884481dd95e289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/691 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a35199c7aa47348edc93585fbc229a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e2397ff8824f72b0ef7e1282c44850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/412 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d4b08b7f88447487742cf9fbb2f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9880e675c7fa4c029b7459f98a1f15f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7226f6c577be44b1b41bb63d74504edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cb616041fb4208bb15c3ad7f334ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f77783a7c6b47eca961575dd9c3df4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "LETTER_MAP = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# ------------------ Load Models ------------------\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\"./biogpt_qa_generation/checkpoint-3185\").to(\"cuda\")\n",
    "zeroshot_model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\"\n",
    "encoder = SentenceTransformer(\"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\")\n",
    "\n",
    "# ------------------ Prompting ------------------\n",
    "def build_prompt(example):\n",
    "    return (\n",
    "        f\"Question: {example['question']}\\n\"\n",
    "        \"Options:\\n\"\n",
    "        f\"A: {example['answers'][0]}\\n\"\n",
    "        f\"B: {example['answers'][1]}\\n\"\n",
    "        f\"C: {example['answers'][2]}\\n\"\n",
    "        f\"D: {example['answers'][3]}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "def format_cot_few_shot_prompt(shot_examples, test_example):\n",
    "    prompt = \"You are a helpful assistant. Eliminate incorrect choices step by step. Then answer with the best option text.\\n\\n\"\n",
    "    for ex in shot_examples:\n",
    "        prompt += build_prompt(ex) + f\"\\nExplanation: Based on context, best answer is\\nAnswer: {ex['answers'][ex['target']]}\\n\\n\"\n",
    "    prompt += build_prompt(test_example)\n",
    "    return prompt\n",
    "\n",
    "# ------------------ Evaluation Methods ------------------\n",
    "def predict_by_scoring(model, tokenizer, example):\n",
    "    prompt = build_prompt(example)\n",
    "    losses = []\n",
    "    for option in example['answers']:\n",
    "        input_text = prompt + \" \" + option\n",
    "        enc = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**enc, labels=enc[\"input_ids\"])\n",
    "            losses.append(output.loss.item())\n",
    "    return int(np.argmin(losses))\n",
    "\n",
    "def predict_by_prompting(model, tokenizer, encoder, example, few_shot_bank):\n",
    "    prompt = format_cot_few_shot_prompt(few_shot_bank, example)\n",
    "    enc = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**enc, max_new_tokens=32)\n",
    "    generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer_text = generated.split(\"Answer:\")[-1].strip().lower()\n",
    "    ans_emb = encoder.encode(answer_text, convert_to_tensor=True)\n",
    "    opt_emb = encoder.encode([a.lower() for a in example['answers']], convert_to_tensor=True)\n",
    "    sim = util.cos_sim(ans_emb, opt_emb)\n",
    "    return int(torch.argmax(sim))\n",
    "\n",
    "def predict_by_finetuned(model, tokenizer, example):\n",
    "    prompt, answer = build_prompt(example), LETTER_MAP[example['target']]\n",
    "    input_text = prompt + \" \" + answer\n",
    "    enc = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    input_ids = enc['input_ids'].to(model.device)\n",
    "    attn = enc['attention_mask'].to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids=input_ids, attention_mask=attn, max_new_tokens=1)\n",
    "    gen = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    for i, opt in enumerate(LETTER_MAP):\n",
    "        if opt in gen:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# ------------------ Ensemble Prediction ------------------\n",
    "def ensemble_predict(example, few_shot_bank):\n",
    "    pred1 = predict_by_finetuned(finetuned_model, tokenizer, example)\n",
    "    pred2 = predict_by_scoring(zeroshot_model, tokenizer, example)\n",
    "    pred3 = predict_by_prompting(zeroshot_model, tokenizer, encoder, example, few_shot_bank)\n",
    "    votes = [pred1, pred2, pred3]\n",
    "    return max(set(votes), key=votes.count)\n",
    "\n",
    "# ------------------ Evaluate Ensemble ------------------\n",
    "def run_ensemble_eval(val_data, train_data):\n",
    "    gold = []\n",
    "    pred = []\n",
    "    bank = random.sample(train_data, 2)  # for few-shot prompting\n",
    "    for ex in tqdm(val_data, desc=\"Ensemble Eval\"):\n",
    "        pred_idx = ensemble_predict(ex, bank)\n",
    "        pred.append(LETTER_MAP[pred_idx])\n",
    "        gold.append(LETTER_MAP[ex['target']])\n",
    "    print(\"\\n✅ Ensemble Accuracy:\", accuracy_score(gold, pred))\n",
    "    print(classification_report(gold, pred, labels=LETTER_MAP))\n",
    "\n",
    "# Example usage:\n",
    "# run_ensemble_eval(validation_data.to_dict(orient=\"records\"), train_data.to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAW230qJzqf0",
    "outputId": "34f99576-fbb5-453e-fab5-151cb06f595c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Eval:   0%|          | 0/1272 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Ensemble Eval: 100%|██████████| 1272/1272 [10:14<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Ensemble Accuracy: 0.2562893081761006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.25      0.80      0.39       330\n",
      "           B       0.29      0.07      0.11       316\n",
      "           C       0.32      0.07      0.11       352\n",
      "           D       0.20      0.06      0.09       274\n",
      "\n",
      "    accuracy                           0.26      1272\n",
      "   macro avg       0.27      0.25      0.18      1272\n",
      "weighted avg       0.27      0.26      0.18      1272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_ensemble_eval(validation_data.to_dict(orient=\"records\"), train_data.to_dict(orient=\"records\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
